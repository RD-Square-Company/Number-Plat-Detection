{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import imutils\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from skimage.feature import hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading of vehicle images done...\n"
     ]
    }
   ],
   "source": [
    "#                           START READING FILES FOR VEHICLES AND NON-VEHICLES\n",
    "# Reading car images\n",
    "vehicle_image_arr1 = glob.glob('/media/rd_square/Important/Image_processing/car_data_with_neg/vehicles/*/*.png')\n",
    "\n",
    "# read images, flip images and append into list\n",
    "vehicle_images_list = []    \n",
    "for imagePath in vehicle_image_arr1:\n",
    "    readImage = cv2.imread(imagePath)\n",
    "    rgbImage = cv2.cvtColor(readImage, cv2.COLOR_BGR2RGB)\n",
    "    rgbImage = cv2.resize(rgbImage, (64,64))\n",
    "    flippedImage = cv2.flip(rgbImage, flipCode=1) # flip horizontally\n",
    "    vehicle_images_list.append(rgbImage)\n",
    "    vehicle_images_list.append(flippedImage)\n",
    "    \n",
    "print(\"Reading of vehicle images done...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading of non vehicle images done...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Reading non car images\n",
    "no_vehicle_image_arr1 = glob.glob('/media/rd_square/Important/Image_processing/car_data_with_neg/non-vehicles/*/*.png')\n",
    "no_vehicle_image_arr2 = glob.glob('/media/rd_square/Important/Image_processing/haar_cascade_classifier/neg/*.jpg')\n",
    "\n",
    "# read images, flip images and append into list\n",
    "no_vehicle_images_list = []\n",
    "for imagePath in no_vehicle_image_arr1:\n",
    "    readImage = cv2.imread(imagePath)\n",
    "    rgbImage = cv2.cvtColor(readImage, cv2.COLOR_BGR2RGB)\n",
    "    rgbImage = cv2.resize(rgbImage, (64,64))\n",
    "    flippedImage = cv2.flip(rgbImage, flipCode=1) # flip horizontally\n",
    "    no_vehicle_images_list.append(rgbImage)\n",
    "    no_vehicle_images_list.append(flippedImage)\n",
    "    \n",
    "for imagePath in no_vehicle_image_arr2:\n",
    "    readImage = cv2.imread(imagePath)\n",
    "    rgbImage = cv2.cvtColor(readImage, cv2.COLOR_BGR2RGB)\n",
    "    rgbImage = cv2.resize(rgbImage, (64,64))\n",
    "    no_vehicle_images_list.append(rgbImage)\n",
    "    \n",
    "    \n",
    "print(\"Reading of non vehicle images done...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Vehicles images:  1150\n",
      "No of non vehicle images:  1038\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"No of Vehicles images: \", len(vehicle_images_list))\n",
    "print(\"No of non vehicle images: \", len(no_vehicle_images_list))\n",
    "#                       ENDING OF READING IMAGES FROM FILES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#                       FEATURE EXTRACTION FROM IMAGES\n",
    "\n",
    "def GetFeaturesFromHog(image, orient, cellsPerBlock, pixelsPerCell,\n",
    "                       visualise=False, feature_vector_flag=True):\n",
    "    'To extract hog feature using hog() from YUV image'\n",
    "    hog_features = hog(image, orientations=orient,\n",
    "                                  pixels_per_cell=(pixelsPerCell, pixelsPerCell),\n",
    "                                  cells_per_block=(cellsPerBlock, cellsPerBlock),\n",
    "                                  visualize=visualise, feature_vector= feature_vector_flag, block_norm='L2-Hys')\n",
    "    return hog_features\n",
    "\n",
    "def ExtractFeatures(images, orientation=9, cellsPerBlock=2, pixelsPerCell=16, convertColorSpace=True):\n",
    "    'Arrangin features into horizontal stack extracted from hog()'\n",
    "    featureList = []\n",
    "    for image in images:\n",
    "        if(convertColorSpace):\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
    "        feature1 = GetFeaturesFromHog(image[:,:,0], orientation, cellsPerBlock, pixelsPerCell)\n",
    "        feature2 = GetFeaturesFromHog(image[:,:,1], orientation, cellsPerBlock, pixelsPerCell)\n",
    "        feature3 = GetFeaturesFromHog(image[:,:,2], orientation, cellsPerBlock, pixelsPerCell)\n",
    "\n",
    "        # Arranging feature into horizontal stack for machine learning model training set\n",
    "        featureListing = np.hstack((feature1, feature2, feature3))\n",
    "        featureList.append(featureListing)\n",
    "    return featureList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of features list is  (2188, 972)\n",
      "Shape of labels list is  (2188,)\n"
     ]
    }
   ],
   "source": [
    "vehicleFeatures = ExtractFeatures(vehicle_images_list)\n",
    "nonVehicleFeatures = ExtractFeatures(no_vehicle_images_list)\n",
    "\n",
    "''' Arranging features into vertical stack for training the machine learning model '''\n",
    "featureList = np.vstack([vehicleFeatures, nonVehicleFeatures])\n",
    "print(\"Shape of features list is \", featureList.shape)\n",
    "labelList = np.concatenate([np.ones(len(vehicleFeatures)), np.zeros(len(nonVehicleFeatures))])\n",
    "print(\"Shape of labels list is \", labelList.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Classifier Trained...\n",
      "Accuracy of trained svm classifier is  0.9954337899543378\n"
     ]
    }
   ],
   "source": [
    "#                       DATA PREPROCESSING\n",
    "\n",
    "# train and test split of data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(featureList, labelList, test_size=0.2, shuffle=True)\n",
    "\n",
    "\n",
    "#                       TRAINING THE LINEAR SUPPORT VECTOR CLASSIFIER MODEL OF MACHINE LEARNING\n",
    "\n",
    "svcClassifier  = LinearSVC()\n",
    "svcClassifier.fit(X_train, Y_train) # training the classifier\n",
    "print(\"Support Vector Classifier Trained...\")\n",
    "print(\"Accuracy of trained svm classifier is \", svcClassifier.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "video = cv2.VideoCapture('camera.mp4') # Capturing video from camera\n",
    "\n",
    "# Initialize the first frame in the video stream\n",
    "firstFrame = None\n",
    "count = 0\n",
    "\n",
    "# loop over the frames of the video\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "\n",
    "    if frame is None:\n",
    "        break\n",
    "\n",
    "\n",
    "    # resize the frame, convert it to grayscale, and blur it\n",
    "    frame = imutils.resize(frame, width=500)\n",
    "    frame = cv2.GaussianBlur(frame, (5,5),0)\n",
    "    movingObject = frame.copy() # Generating copy of image for future use\n",
    "\n",
    "    # Edge detection using canny edge detection method\n",
    "    edges = cv2.Canny(frame, 100,200)\n",
    "    \n",
    "    #edges = cv2.adaptiveThreshold(frame1,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,4)\n",
    "\n",
    "        \n",
    "    # if the first frame is None, initialize it\n",
    "    if firstFrame is None:\n",
    "        firstFrame = edges\n",
    "        continue\n",
    "\n",
    "    if count > 20:\n",
    "        firstFrame = edges\n",
    "        count = 0\n",
    "        continue\n",
    "    else:\n",
    "        count += 1\n",
    "\n",
    "    ''' bitwise_and with firstFrame will give only static\n",
    "    elements edges in white color which will be further changed into black\n",
    "    for another bitwise_and to get moving elements'''\n",
    "    maskImage = cv2.bitwise_and(firstFrame, edges)\n",
    "    \n",
    "    cv2.imshow(\"maskImage\", maskImage)\n",
    "    \n",
    "    ''' Inversion after thresholding\n",
    "    to make lines black and background white so when\n",
    "    we do bitwise_and with real edges image, it will only give\n",
    "    moving elements by setting other all to zero or black'''\n",
    "    maskImage = cv2.threshold(maskImage, 254, 255, cv2.THRESH_BINARY_INV)[1]\n",
    "    cv2.imshow(\"inverted mask image\", maskImage)\n",
    "\n",
    "    ''' bitwise_and with edges and maskImage will give a moving elements image'''\n",
    "    carImage = cv2.bitwise_and(edges, maskImage)\n",
    "    \n",
    "    cv2.imshow(\"car image\", carImage)\n",
    "\n",
    "    ''' Closing morphological transformation will close black hole in white lines\n",
    "    of edges of moving elements to help in making better contours'''\n",
    "    carImage = cv2.morphologyEx(carImage, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_RECT, (5,5)))\n",
    "    #carImage = cv2.dilate(carImage, cv2.getStructuringElement(cv2.MORPH_RECT, (7,7)))\n",
    "\n",
    "    # Finding contours of moving element image\n",
    "    cnts = cv2.findContours(carImage.copy(), cv2.RETR_EXTERNAL,\n",
    "                            cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "    temp = carImage.copy()\n",
    "    # Drawing contours in the image for visualization\n",
    "    for c in cnts:\n",
    "        #if cv2.contourArea(c) < 200:\n",
    "            #continue\n",
    "        (x,y,w,h) = cv2.boundingRect(c)\n",
    "        \n",
    "        # Extracting moving object image and detecting cars\n",
    "        clippedImage = frame[y:y+h, x:x+w]\n",
    "        clippedImage1 = cv2.resize(clippedImage, (64,64))\n",
    "        clippedFeature = ExtractFeatures([clippedImage1])\n",
    "        predictedOutput = svcClassifier.predict([clippedFeature[0]])\n",
    "        \n",
    "        if (predictedOutput == 1):\n",
    "            cv2.rectangle(movingObject, (x,y), (x+w,y+h),(0,255,0),2)\n",
    "            \n",
    "            # finding hull of image\n",
    "            hull = cv2.convexHull(c)\n",
    "            cv2.drawContours(temp, [hull], -1, 255, -1) # drawing hull on image\n",
    "            cv2.imshow(\"new frame with hull\", temp)\n",
    "            #cv2.imshow('1 - detected car', clippedImage)\n",
    "        #else:\n",
    "        #    cv2.imshow('0 - Not detected car', clippedImage)\n",
    "\n",
    "        \n",
    "    cv2.imshow('Moving Object Detected Frame', movingObject)\n",
    "      \n",
    "    \n",
    "    k = cv2.waitKey(0)\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
